"""
_integration tests for /v1/messages endpoint

Ù›KÕŒï¿½t*ï¿½B-Í”Aï¿½pnlbï¿½OpenAI APIï¿½
"""

import pytest
from fastapi.testclient import TestClient
from unittest.mock import AsyncMock, patch, MagicMock
import json

from src.main import app
from src.models.anthropic import AnthropicRequest
from src.models.openai import OpenAIRequest, OpenAIResponse


class TestMessagesEndpoint:
    """Kï¿½ /v1/messages ï¹Ÿï¿½"""

    @pytest.fixture
    def client(self):
        """ï¿½KÕ¢7ï¿½"""
        return TestClient(app)

    @pytest.fixture
    def valid_anthropic_request(self):
        """	Hï¿½Anthropicï¿½B:ï¿½"""
        return {
            "model": "claude-3-5-sonnet-20241022",
            "max_tokens": 100,
            "messages": [
                {
                    "role": "user",
                    "content": "Hello, how are you?"
                }
            ]
        }

    @pytest.fixture
    def mock_openai_response(self):
        """Mockï¿½OpenAIÍ”"""
        return {
            "id": "chatcmpl-123",
            "object": "chat.completion",
            "created": 1700000000,
            "model": "gpt-3.5-turbo",
            "choices": [
                {
                    "index": 0,
                    "message": {
                        "role": "assistant",
                        "content": "I'm doing well! How can I help you today?"
                    },
                    "finish_reason": "stop"
                }
            ],
            "usage": {
                "prompt_tokens": 10,
                "completion_tokens": 15,
                "total_tokens": 25
            }
        }

    def test_endpoint_exists(self, client):
        """ï¿½ï¿½ï¿½X("""
        response = client.post("/v1/messages", json={"model": "test"})
        assert response.status_code != 404

    def test_invalid_request_format(self, client):
        """Kï¿½ï¿½Hï¿½B<"""
        response = client.post("/v1/messages", json={"invalid": "format"})
        assert response.status_code == 422

    def test_missing_required_fields(self, client):
        """Kï¿½:ï¿½kWï¿½"""
        response = client.post("/v1/messages", json={"model": "test"})
        assert response.status_code == 422

    def test_empty_messages(self, client):
        """Kï¿½zï¿½oh"""
        request = {
            "model": "claude-3-5-sonnet-20241022",
            "messages": [],
            "max_tokens": 100
        }
        response = client.post("/v1/messages", json=request)
        assert response.status_code == 422

    @patch('src.handlers.messages.MessagesHandler.process_message')
    @pytest.mark.asyncio
    async def test_successful_non_streaming_request(
        self, mock_process, client, valid_anthropic_request, mock_openai_response
    ):
        """Kï¿½ï¿½ï¿½^Aï¿½B"""
        from src.models.anthropic import AnthropicMessageResponse
        
        # ï¿½ï¿½ï¿½AnthropicÍ”
        expected_response = AnthropicMessageResponse(
            id="msg_123",
            type="message",
            role="assistant",
            content=[{"type": "text", "text": "I'm doing well! How can I help you today?"}],
            model="claude-3-5-sonnet-20241022",
            stop_reason="end_turn",
            usage={"input_tokens": 10, "output_tokens": 15}
        )
        
        mock_process.return_value = expected_response
        
        response = client.post("/v1/messages", json=valid_anthropic_request)
        
        assert response.status_code == 200
        response_data = response.json()
        
        assert response_data["type"] == "message"
        assert response_data["role"] == "assistant"
        assert len(response_data["content"]) > 0
        assert response_data["content"][0]["type"] == "text"
        assert response_data["model"] == "claude-3-5-sonnet-20241022"
        assert "usage" in response_data

    @patch('src.handlers.messages.MessagesHandler.process_stream_message')
    @pytest.mark.asyncio
    async def test_successful_streaming_request(
        self, mock_stream, client, valid_anthropic_request, mock_openai_response
    ):
        """Kï¿½ï¿½ï¿½Aï¿½B"""
        valid_anthropic_request["stream"] = True
        
        # !ï¿½AÍ”
        async def mock_generator():
            yield 'event: content_block_start\ndata: {"type": "content_block_start", "index": 0, "content_block": {"type": "text", "text": ""}}\n\n'
            yield 'event: content_block_delta\ndata: {"type": "content_block_delta", "index": 0, "delta": {"type": "text_delta", "text": "Hello"}}\n\n'
            yield 'event: message_stop\ndata: {"type": "message_stop"}\n\n'
        
        mock_stream.return_value = mock_generator()
        
        response = client.post("/v1/messages", json=valid_anthropic_request)
        
        assert response.status_code == 200
        assert response.headers["content-type"] == "text/event-stream; charset=utf-8"
        
        lines = response.content.decode('utf-8').split('\\n')
        assert any('content_block_start' in line for line in lines)

    def test_system_message_support(self, client):
        """Kï¿½ï¿½ßˆo/"""
        request = {
            "model": "claude-3-5-sonnet-20241022",
            "messages": [{"role": "user", "content": "Hello"}],
            "system": [{
                "type": "text",
                "text": "You are a helpful assistant"
            }],
            "max_tokens": 100
        }
        
        response = client.post("/v1/messages", json=request)
        assert response.status_code != 400

    def test_tool_definition_support(self, client):
        """Kï¿½ï¿½wï¿½I/"""
        request = {
            "model": "claude-3-5-sonnet-20241022",
            "messages": [{"role": "user", "content": "Hello"}],
            "tools": [
                {
                    "name": "get_weather",
                    "description": "Get weather information",
                    "input_schema": {
                        "type": "object",
                        "properties": {
                            "location": {"type": "string"}
                        },
                        "required": ["location"]
                    }
                }
            ],
            "max_tokens": 100
        }
        
        response = client.post("/v1/messages", json=request)
        assert response.status_code != 400

    def test_temperature_parameter(self, client):
        """Kï¿½temperatureï¿½p"""
        request = {
            "model": "claude-3-5-sonnet-20241022",
            "messages": [{"role": "user", "content": "Hello"}],
            "temperature": 0.5,
            "max_tokens": 100
        }
        
        response = client.post("/v1/messages", json=request)
        # ï¿½ï¿½ÇŒï¿½ï¿½Eï¿½ï¿½1converter
        assert response.status_code != 422

    def test_max_tokens_parameter(self, client):
        """Kï¿½max_tokensï¿½p"""
        request = {
            "model": "claude-3-5-sonnet-20241022",
            "messages": [{"role": "user", "content": "Hello"}],
            "max_tokens": 1000
        }
        
        response = client.post("/v1/messages", json=request)
        assert response.status_code != 422

    def test_top_p_parameter(self, client):
        """Kï¿½top_pï¿½p"""
        request = {
            "model": "claude-3-5-sonnet-20241022",
            "messages": [{"role": "user", "content": "Hello"}],
            "top_p": 0.9,
            "max_tokens": 100
        }
        
        response = client.post("/v1/messages", json=request)
        assert response.status_code != 422

    def test_stop_sequences_parameter(self, client):
        """Kï¿½stop_sequencesï¿½p"""
        request = {
            "model": "claude-3-5-sonnet-20241022",
            "messages": [{"role": "user", "content": "Hello"}],
            "stop_sequences": ["\n\n"],
            "max_tokens": 100
        }
        
        response = client.post("/v1/messages", json=request)
        assert response.status_code != 422

    def test_metadata_parameter(self, client):
        """Kï¿½metadataï¿½p"""
        request = {
            "model": "claude-3-5-sonnet-20241022",
            "messages": [{"role": "user", "content": "Hello"}],
            "metadata": {"trace_id": "123456"},
            "max_tokens": 100
        }
        
        response = client.post("/v1/messages", json=request)
        assert response.status_code != 422

    def test_image_content_support(self, client):
        """Kï¿½ï¿½Ï…ï¿½/"""
        request = {
            "model": "claude-3-5-sonnet-20241022",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "What's in this image?"},
                        {
                            "type": "image",
                            "source": {
                                "type": "base64",
                                "media_type": "image/jpeg",
                                "data": "base64_data_here"
                            }
                        }
                    ]
                }
            ],
            "max_tokens": 100
        }
        
        response = client.post("/v1/messages", json=request)
        assert response.status_code != 422

    @patch.dict('src.models.config.Config', {'openai': {'api_key': 'test-key'}})
    def test_environment_variables(self, client):
        """KÕ¯ï¿½ï¿½ï¿½Mn"""
        # ï¿½ï¿½Mnï¿½ï¿½ï¿½
        response = client.post("/v1/messages", json={
            "model": "claude-3-5-sonnet-20241022",
            "messages": [{"role": "user", "content": "Hello"}],
            "max_tokens": 100
        })
        
        # Config import
        assert response.status_code != 500

    def test_error_response_format(self, client):
        """Kï¿½ï¿½Í”<&Anthropicï¿½"""
        response = client.post("/v1/messages", json={"invalid": "format"})
        
        assert response.status_code == 422
        error_data = response.json()
        
        # ï¿½ï¿½ï¿½<+ï¿½Wï¿½
        assert "type" in error_data
        assert "error" in error_data
        assert "type" in error_data["error"]
        assert "message" in error_data["error"]

    def test_all_required_fields_present(self, client):
        """Kï¿½ï¿½kWï¿½ï¿½t'"""
        required_fields = [
            "model",
            "messages", 
            "max_tokens"
        ]
        
        for field in required_fields:
            base_request = {
                "model": "claude-3-5-sonnet-20241022",
                "messages": [{"role": "user", "content": "Hello"}],
                "max_tokens": 100
            }
            
            # ï¿½dï¿½kWï¿½
            del base_request[field]
            
            response = client.post("/v1/messages", json=base_request)
            assert response.status_code == 422